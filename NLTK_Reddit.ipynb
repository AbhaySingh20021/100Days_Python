{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-t490aym5j6AfV26haLBRmZlsOtezYTS",
      "authorship_tag": "ABX9TyPFnc5UJ6OGxCgRYIGPl3ph",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhaySingh20021/100Days_Python/blob/master/NLTK_Reddit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8ilCsiqog9K",
        "outputId": "9c550ca9-0abb-40aa-c03b-548d265c745f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaHCQZmCpOVu",
        "outputId": "6ea4d387-8606-47c3-eefd-3a88b7bfca73"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"/content/drive/MyDrive/India_Games_Reddit_Comments/IndvsPak_loss.csv\",sep = '|')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "APgt0sAkpr9J",
        "outputId": "371ba28a-15b9-4d8f-f8ef-56cd8a1e6c4f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0 Subreddit Post ID Comment ID          Author  Score  \\\n",
              "0           0   Cricket  x5lyrw    in2g53t         Jerry_-    312   \n",
              "1           1   Cricket  x5lyrw    in1yibs      vapeshapes    233   \n",
              "2           2   Cricket  x5lyrw    in25rl4   getyoutogabba    206   \n",
              "3           3   Cricket  x5lyrw    in2zyzu  dmcMethematics    182   \n",
              "4           4   Cricket  x5lyrw    in1vsxl            vpsj    169   \n",
              "\n",
              "        Created                                               Body  \n",
              "0  1.662307e+09  Can't believe we brought in Pant instead of DK...  \n",
              "1  1.662300e+09  Cricket Twitter wants Babar Azam to captain li...  \n",
              "2  1.662303e+09            “Breeding them young”…the fuck was that  \n",
              "3  1.662315e+09  Mfs inviting all asian cricket playing nations...  \n",
              "4  1.662298e+09  Babar: Tails!\\n\\nShastri: Heads is the call! \\...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32a7b0c9-6015-4bd5-b359-279d052a7ac1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Subreddit</th>\n",
              "      <th>Post ID</th>\n",
              "      <th>Comment ID</th>\n",
              "      <th>Author</th>\n",
              "      <th>Score</th>\n",
              "      <th>Created</th>\n",
              "      <th>Body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Cricket</td>\n",
              "      <td>x5lyrw</td>\n",
              "      <td>in2g53t</td>\n",
              "      <td>Jerry_-</td>\n",
              "      <td>312</td>\n",
              "      <td>1.662307e+09</td>\n",
              "      <td>Can't believe we brought in Pant instead of DK...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Cricket</td>\n",
              "      <td>x5lyrw</td>\n",
              "      <td>in1yibs</td>\n",
              "      <td>vapeshapes</td>\n",
              "      <td>233</td>\n",
              "      <td>1.662300e+09</td>\n",
              "      <td>Cricket Twitter wants Babar Azam to captain li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Cricket</td>\n",
              "      <td>x5lyrw</td>\n",
              "      <td>in25rl4</td>\n",
              "      <td>getyoutogabba</td>\n",
              "      <td>206</td>\n",
              "      <td>1.662303e+09</td>\n",
              "      <td>“Breeding them young”…the fuck was that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Cricket</td>\n",
              "      <td>x5lyrw</td>\n",
              "      <td>in2zyzu</td>\n",
              "      <td>dmcMethematics</td>\n",
              "      <td>182</td>\n",
              "      <td>1.662315e+09</td>\n",
              "      <td>Mfs inviting all asian cricket playing nations...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Cricket</td>\n",
              "      <td>x5lyrw</td>\n",
              "      <td>in1vsxl</td>\n",
              "      <td>vpsj</td>\n",
              "      <td>169</td>\n",
              "      <td>1.662298e+09</td>\n",
              "      <td>Babar: Tails!\\n\\nShastri: Heads is the call! \\...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32a7b0c9-6015-4bd5-b359-279d052a7ac1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32a7b0c9-6015-4bd5-b359-279d052a7ac1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32a7b0c9-6015-4bd5-b359-279d052a7ac1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "stop = stopwords.words('english')\n",
        "\n",
        "\n",
        "pos_tweets = data['Body']\n",
        "post_tweet2 = [re.sub('[^a-zA-Z0-9]+', ' ' ,  _) for _ in pos_tweets]\n",
        "\n",
        "\n",
        "test = pd.DataFrame(pos_tweets)\n",
        "test1 = pd.DataFrame(post_tweet2 )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test1.columns = [\"Body\"]\n",
        "\n",
        "\n",
        "\n",
        "test[\"Comments without stopwords\"] = test1[\"Body\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "aN1YC8KdpxtR",
        "outputId": "43d5d278-37ef-4278-af14-776a8b324b7a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    Body  \\\n",
              "0      Can't believe we brought in Pant instead of DK...   \n",
              "1      Cricket Twitter wants Babar Azam to captain li...   \n",
              "2                “Breeding them young”…the fuck was that   \n",
              "3      Mfs inviting all asian cricket playing nations...   \n",
              "4      Babar: Tails!\\n\\nShastri: Heads is the call! \\...   \n",
              "...                                                  ...   \n",
              "23532  Right! It's awesome that you are still followi...   \n",
              "23533            Ok , last question. What does T20 mean?   \n",
              "23534  Well there are formats in this game this one i...   \n",
              "23535  Ah, so basically it determines length of match...   \n",
              "23536  Right this one typically last around 3-4 hours...   \n",
              "\n",
              "                              Comments without stopwords  \n",
              "0      Can believe brought Pant instead DK could left...  \n",
              "1      Cricket Twitter wants Babar Azam captain like ...  \n",
              "2                                    Breeding young fuck  \n",
              "3      Mfs inviting asian cricket playing nations ind...  \n",
              "4                     Babar Tails Shastri Heads call Lol  \n",
              "...                                                  ...  \n",
              "23532                   Right It awesome still following  \n",
              "23533                     Ok last question What T20 mean  \n",
              "23534  Well formats game one 20 20 T20 basically team...  \n",
              "23535  Ah basically determines length matches Makes s...  \n",
              "23536  Right one typically last around 3 4 hours ODI ...  \n",
              "\n",
              "[23537 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4936dc2-bd86-4ea6-b768-259de9460963\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body</th>\n",
              "      <th>Comments without stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Can't believe we brought in Pant instead of DK...</td>\n",
              "      <td>Can believe brought Pant instead DK could left...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cricket Twitter wants Babar Azam to captain li...</td>\n",
              "      <td>Cricket Twitter wants Babar Azam captain like ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>“Breeding them young”…the fuck was that</td>\n",
              "      <td>Breeding young fuck</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mfs inviting all asian cricket playing nations...</td>\n",
              "      <td>Mfs inviting asian cricket playing nations ind...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Babar: Tails!\\n\\nShastri: Heads is the call! \\...</td>\n",
              "      <td>Babar Tails Shastri Heads call Lol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23532</th>\n",
              "      <td>Right! It's awesome that you are still followi...</td>\n",
              "      <td>Right It awesome still following</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23533</th>\n",
              "      <td>Ok , last question. What does T20 mean?</td>\n",
              "      <td>Ok last question What T20 mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23534</th>\n",
              "      <td>Well there are formats in this game this one i...</td>\n",
              "      <td>Well formats game one 20 20 T20 basically team...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23535</th>\n",
              "      <td>Ah, so basically it determines length of match...</td>\n",
              "      <td>Ah basically determines length matches Makes s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23536</th>\n",
              "      <td>Right this one typically last around 3-4 hours...</td>\n",
              "      <td>Right one typically last around 3 4 hours ODI ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23537 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4936dc2-bd86-4ea6-b768-259de9460963')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e4936dc2-bd86-4ea6-b768-259de9460963 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e4936dc2-bd86-4ea6-b768-259de9460963');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from itertools import islice\n",
        "\n",
        "limit = 5\n",
        "\n",
        "\n",
        "for w in  islice(test[\"Body\"], limit):\n",
        "\t\tprint(\"Lemma for {} is {}\".format(w, wordnet_lemmatizer.lemmatize(w))) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kcis5DgKsnOS",
        "outputId": "935fb108-247c-4706-c8eb-7546a9c6824f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemma for Can't believe we brought in Pant instead of DK so that we could have a left hander in the team and the mfer decided to become a right hander and get out instead. is Can't believe we brought in Pant instead of DK so that we could have a left hander in the team and the mfer decided to become a right hander and get out instead.\n",
            "Lemma for Cricket Twitter wants Babar Azam to captain like Ricky Ponting, bat like Jaywardane, field like Jonty Rhodes, think like MS Dhoni, hit like Jos Buttler, perform like Jacque Kallis, keep like Gilichrist, bowl like Wasim Akram, speak like Kohli and umpire like Aleem Dar. is Cricket Twitter wants Babar Azam to captain like Ricky Ponting, bat like Jaywardane, field like Jonty Rhodes, think like MS Dhoni, hit like Jos Buttler, perform like Jacque Kallis, keep like Gilichrist, bowl like Wasim Akram, speak like Kohli and umpire like Aleem Dar.\n",
            "Lemma for “Breeding them young”…the fuck was that is “Breeding them young”…the fuck was that\n",
            "Lemma for Mfs inviting all asian cricket playing nations just to have ind vs pak bilateral is Mfs inviting all asian cricket playing nations just to have ind vs pak bilateral\n",
            "Lemma for Babar: Tails!\n",
            "\n",
            "Shastri: Heads is the call! \n",
            "\n",
            "Lol is Babar: Tails!\n",
            "\n",
            "Shastri: Heads is the call! \n",
            "\n",
            "Lol\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = u'This dog \\U0001f602'\n",
        "print(test1[\"Body\"]) # with emoji\n",
        "\n",
        "emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "print(emoji_pattern.sub(r'', text)) # no emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIZ869Z6wgBr",
        "outputId": "3a0a6753-3356-4dce-94ea-d489956446f8"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        Can t believe we brought in Pant instead of DK...\n",
            "1        Cricket Twitter wants Babar Azam to captain li...\n",
            "2                    Breeding them young the fuck was that\n",
            "3        Mfs inviting all asian cricket playing nations...\n",
            "4                Babar Tails Shastri Heads is the call Lol\n",
            "                               ...                        \n",
            "23532    Right It s awesome that you are still followin...\n",
            "23533                 Ok last question What does T20 mean \n",
            "23534    Well there are formats in this game this one i...\n",
            "23535    Ah so basically it determines length of matche...\n",
            "23536    Right this one typically last around 3 4 hours...\n",
            "Name: Body, Length: 23537, dtype: object\n",
            "This dog \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "limit = 20\n",
        "for x in islice(test1[\"Body\"], limit):\n",
        "  Data_Without_Urls  = re.sub(\"#\\S*\\s\", \"\", x)\n",
        "  print(Data_Without_Urls)\n",
        "  \n",
        "  \n",
        "\n",
        "   \n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elQHEEf7xlYp",
        "outputId": "80c5c08d-1a3c-4c1b-f305-67a44b4b6436"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Can t believe we brought in Pant instead of DK so that we could have a left hander in the team and the mfer decided to become a right hander and get out instead \n",
            "Cricket Twitter wants Babar Azam to captain like Ricky Ponting bat like Jaywardane field like Jonty Rhodes think like MS Dhoni hit like Jos Buttler perform like Jacque Kallis keep like Gilichrist bowl like Wasim Akram speak like Kohli and umpire like Aleem Dar \n",
            " Breeding them young the fuck was that\n",
            "Mfs inviting all asian cricket playing nations just to have ind vs pak bilateral\n",
            "Babar Tails Shastri Heads is the call Lol\n",
            "Lmao DK looks pissed He looks exactly like a guy who got dropped of no fault of his own \n",
            "KL try to not look depressed challenge impossible \n",
            "GG in commentary box Only thing that stops KL from playing well is KL himself I love GG lol\n",
            "Rohit has clearly fucking grilled the team about making sure they stick to his approach of aggression There s no way Rahul would show this much intent by himself \n",
            "Hasnain was 7 when Rohit made his debut Naseem was 4\n",
            "Bro you re in the side cuz you re a left hander and this man gets out becoming a right hander\n",
            "If koach wakes me up at 3 AM and says run i will run No questions asked\n",
            " Tails Heads is the call\n",
            " Breeding then young fuck me \n",
            "Rishabh Pant when he sweats a lot Rishabh Pants\n",
            "Rauf deserved better Madlad nailed a laser guided 150kmph Yorker to a Set Kohli only to get Shithoused by Bishnoi and Fakhar\n",
            "Rohit sharma after shouting at multiple players including a really long lecture to pant when he got out I think we were quite calm today \n",
            "On a side note cricket made it to main page of reddit twice in 10 days\n",
            "So nice to see Rohit setting the tone of the innings early on That s why i don t mind even when he fails you need to make the bowlers nervous in T20 and throw them off their line\n",
            "Chad Koach making sure pant doesnt skip cardio today\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.pos_tag(test[\"Body\"])\n",
        "nltk.download('brown')\n",
        "\n",
        "# Word similarity using a pre-tagged text\n",
        "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())\n",
        "text.similar('woman')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9A90vQzyaY_",
        "outputId": "22741843-7560-49e7-9381-88419edc9c59"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "man time day year car moment world house family child country boy\n",
            "state job place way war girl work word\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import brown\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "brown_news_tagged = brown.tagged_words(categories='news', tagset='universal')\n",
        "tag_fd = nltk.FreqDist(tag for (word, tag) in brown_news_tagged)\n",
        "tag_fd.most_common()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo93oz_RzB43",
        "outputId": "23b3942a-8378-4a4b-ffc3-a22fccc9c6f2"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('NOUN', 30654),\n",
              " ('VERB', 14399),\n",
              " ('ADP', 12355),\n",
              " ('.', 11928),\n",
              " ('DET', 11389),\n",
              " ('ADJ', 6706),\n",
              " ('ADV', 3349),\n",
              " ('CONJ', 2717),\n",
              " ('PRON', 2535),\n",
              " ('PRT', 2264),\n",
              " ('NUM', 2166),\n",
              " ('X', 92)]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "brown_lrnd_tagged = brown.tagged_words(categories='learned', tagset='universal')\n",
        "tags = [b[1] for (a, b) in nltk.bigrams(brown_lrnd_tagged) if a[0] == 'often']\n",
        "fd = nltk.FreqDist(tags)\n",
        "fd.tabulate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX09hHz1zNGJ",
        "outputId": "af32865c-397b-4410-e785-ffa7b82c1b33"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VERB  ADV  ADP  ADJ    .  PRT \n",
            "  37    8    7    6    4    2 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import brown\n",
        "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
        "brown_sents = brown.sents(categories='news')\n",
        "\n",
        "\n",
        "tags = [tag for (word, tag) in brown.tagged_words(categories='news')]\n",
        "nltk.FreqDist(tags).max()\n",
        "#POS tag for Single Sentence\n",
        "tokens = word_tokenize(test[\"Body\"][0])  \n",
        "default_tagger = nltk.DefaultTagger('NN')\n",
        "default_tagger.tag(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W43RyV0TzPh9",
        "outputId": "90227ae3-7443-497b-c0bc-0b015e8a2a19"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Ca', 'NN'),\n",
              " (\"n't\", 'NN'),\n",
              " ('believe', 'NN'),\n",
              " ('we', 'NN'),\n",
              " ('brought', 'NN'),\n",
              " ('in', 'NN'),\n",
              " ('Pant', 'NN'),\n",
              " ('instead', 'NN'),\n",
              " ('of', 'NN'),\n",
              " ('DK', 'NN'),\n",
              " ('so', 'NN'),\n",
              " ('that', 'NN'),\n",
              " ('we', 'NN'),\n",
              " ('could', 'NN'),\n",
              " ('have', 'NN'),\n",
              " ('a', 'NN'),\n",
              " ('left', 'NN'),\n",
              " ('hander', 'NN'),\n",
              " ('in', 'NN'),\n",
              " ('the', 'NN'),\n",
              " ('team', 'NN'),\n",
              " ('and', 'NN'),\n",
              " ('the', 'NN'),\n",
              " ('mfer', 'NN'),\n",
              " ('decided', 'NN'),\n",
              " ('to', 'NN'),\n",
              " ('become', 'NN'),\n",
              " ('a', 'NN'),\n",
              " ('right', 'NN'),\n",
              " ('hander', 'NN'),\n",
              " ('and', 'NN'),\n",
              " ('get', 'NN'),\n",
              " ('out', 'NN'),\n",
              " ('instead', 'NN'),\n",
              " ('.', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "from collections import Counter\n",
        "def extract_ner_count(tagged):\n",
        "    entities = {}\n",
        "    chunks = nltk.ne_chunk(tagged)\n",
        "    for chunk in chunks:\n",
        "        if type(chunk) is nltk.Tree:\n",
        "          #if you don't need the entities, just add the label directly rather than this.\n",
        "          t = ''.join(c[0] for c in chunk.leaves())\n",
        "          entities[t] = chunk.label()\n",
        "    return Counter(entities.values())\n",
        "\n",
        "data['tokenize'] = data.apply(lambda row: nltk.word_tokenize(row['Body']), axis=1)\n",
        "data['pos_tags'] = data.apply(lambda row: nltk.pos_tag(row['tokenize']), axis=1)\n",
        "data['entityrecognition']=data.apply(lambda row: extract_ner_count(row['pos_tags']), axis=1)\n",
        "data = pd.concat([data, pd.DataFrame(list(data[\"entityrecognition\"]))], axis=1)\n",
        "\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSDc7yCf1MAG",
        "outputId": "06cdbac4-bce2-4c4a-cc1f-25bdbcab72a9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0 Subreddit Post ID Comment ID          Author  Score  \\\n",
            "0           0   Cricket  x5lyrw    in2g53t         Jerry_-    312   \n",
            "1           1   Cricket  x5lyrw    in1yibs      vapeshapes    233   \n",
            "2           2   Cricket  x5lyrw    in25rl4   getyoutogabba    206   \n",
            "3           3   Cricket  x5lyrw    in2zyzu  dmcMethematics    182   \n",
            "4           4   Cricket  x5lyrw    in1vsxl            vpsj    169   \n",
            "\n",
            "        Created                                               Body  \\\n",
            "0  1.662307e+09  Can't believe we brought in Pant instead of DK...   \n",
            "1  1.662300e+09  Cricket Twitter wants Babar Azam to captain li...   \n",
            "2  1.662303e+09            “Breeding them young”…the fuck was that   \n",
            "3  1.662315e+09  Mfs inviting all asian cricket playing nations...   \n",
            "4  1.662298e+09  Babar: Tails!\\n\\nShastri: Heads is the call! \\...   \n",
            "\n",
            "                                            tokenize  \\\n",
            "0  [Ca, n't, believe, we, brought, in, Pant, inst...   \n",
            "1  [Cricket, Twitter, wants, Babar, Azam, to, cap...   \n",
            "2  [“, Breeding, them, young, ”, …the, fuck, was,...   \n",
            "3  [Mfs, inviting, all, asian, cricket, playing, ...   \n",
            "4  [Babar, :, Tails, !, Shastri, :, Heads, is, th...   \n",
            "\n",
            "                                            pos_tags  \\\n",
            "0  [(Ca, NNP), (n't, RB), (believe, VB), (we, PRP...   \n",
            "1  [(Cricket, NNP), (Twitter, NNP), (wants, VBZ),...   \n",
            "2  [(“, NN), (Breeding, NNP), (them, PRP), (young...   \n",
            "3  [(Mfs, NNP), (inviting, VBG), (all, DT), (asia...   \n",
            "4  [(Babar, NN), (:, :), (Tails, NNS), (!, .), (S...   \n",
            "\n",
            "                   entityrecognition  GPE  PERSON  ORGANIZATION  GSP  \\\n",
            "0                         {'GPE': 1}  1.0     NaN           NaN  NaN   \n",
            "1  {'PERSON': 10, 'ORGANIZATION': 3}  NaN    10.0           3.0  NaN   \n",
            "2                                 {}  NaN     NaN           NaN  NaN   \n",
            "3                                 {}  NaN     NaN           NaN  NaN   \n",
            "4            {'GPE': 1, 'PERSON': 1}  1.0     1.0           NaN  NaN   \n",
            "\n",
            "   FACILITY  LOCATION  \n",
            "0       NaN       NaN  \n",
            "1       NaN       NaN  \n",
            "2       NaN       NaN  \n",
            "3       NaN       NaN  \n",
            "4       NaN       NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from collections import Counter\n",
        "\n",
        "tagger = nltk.PerceptronTagger()\n",
        "chunker = nltk.data.load(nltk.chunk._MULTICLASS_NE_CHUNKER)\n",
        "NE_Types = {'GPE', 'ORGANIZATION', 'LOCATION', 'GSP', 'O', 'FACILITY', 'PERSON'}\n",
        "\n",
        "def extract_ner_count(text):\n",
        "    c = Counter()\n",
        "    chunks = chunker.parse(tagger.tag(nltk.word_tokenize(text,preserve_line=True)))\n",
        "    for chunk in chunks:\n",
        "        if type(chunk) is nltk.Tree:\n",
        "            c.update([chunk.label()])\n",
        "    return c\n",
        "\n",
        "\n",
        "for NE_Type in NE_Types:\n",
        "    data[NE_Type] = 0\n",
        "data.update(list(data[\"Body\"].apply(extract_ner_count)))\n",
        "\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F_3xZuzz9QY",
        "outputId": "b3fc9f4b-dc32-476f-c8a7-6f038218845f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0 Subreddit Post ID Comment ID          Author  Score  \\\n",
            "0           0   Cricket  x5lyrw    in2g53t         Jerry_-    312   \n",
            "1           1   Cricket  x5lyrw    in1yibs      vapeshapes    233   \n",
            "2           2   Cricket  x5lyrw    in25rl4   getyoutogabba    206   \n",
            "3           3   Cricket  x5lyrw    in2zyzu  dmcMethematics    182   \n",
            "4           4   Cricket  x5lyrw    in1vsxl            vpsj    169   \n",
            "\n",
            "        Created                                               Body  \\\n",
            "0  1.662307e+09  Can't believe we brought in Pant instead of DK...   \n",
            "1  1.662300e+09  Cricket Twitter wants Babar Azam to captain li...   \n",
            "2  1.662303e+09            “Breeding them young”…the fuck was that   \n",
            "3  1.662315e+09  Mfs inviting all asian cricket playing nations...   \n",
            "4  1.662298e+09  Babar: Tails!\\n\\nShastri: Heads is the call! \\...   \n",
            "\n",
            "                                            tokenize  \\\n",
            "0  [Ca, n't, believe, we, brought, in, Pant, inst...   \n",
            "1  [Cricket, Twitter, wants, Babar, Azam, to, cap...   \n",
            "2  [“, Breeding, them, young, ”, …the, fuck, was,...   \n",
            "3  [Mfs, inviting, all, asian, cricket, playing, ...   \n",
            "4  [Babar, :, Tails, !, Shastri, :, Heads, is, th...   \n",
            "\n",
            "                                            pos_tags  \\\n",
            "0  [(Ca, NNP), (n't, RB), (believe, VB), (we, PRP...   \n",
            "1  [(Cricket, NNP), (Twitter, NNP), (wants, VBZ),...   \n",
            "2  [(“, NN), (Breeding, NNP), (them, PRP), (young...   \n",
            "3  [(Mfs, NNP), (inviting, VBG), (all, DT), (asia...   \n",
            "4  [(Babar, NN), (:, :), (Tails, NNS), (!, .), (S...   \n",
            "\n",
            "                   entityrecognition  GPE  PERSON  ORGANIZATION  GSP  \\\n",
            "0                         {'GPE': 1}  1.0     0.0           0.0  0.0   \n",
            "1  {'PERSON': 10, 'ORGANIZATION': 3}  0.0    10.0           3.0  0.0   \n",
            "2                                 {}  0.0     0.0           0.0  0.0   \n",
            "3                                 {}  0.0     0.0           0.0  0.0   \n",
            "4            {'GPE': 1, 'PERSON': 1}  1.0     1.0           0.0  0.0   \n",
            "\n",
            "   FACILITY  LOCATION  O  \n",
            "0       0.0       0.0  0  \n",
            "1       0.0       0.0  0  \n",
            "2       0.0       0.0  0  \n",
            "3       0.0       0.0  0  \n",
            "4       0.0       0.0  0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.parse.stanford import StanfordDependencyParser\n",
        "\n",
        "\n",
        "\n",
        "path_to_jar = '/content/drive/MyDrive/Dependency/stanford-parser.jar'\n",
        "path_to_models_jar = '/content/drive/MyDrive/Dependency/stanford-parser-4.2.0-models.jar'\n",
        "\n",
        "\n",
        "\n",
        "dependency_parser = StanfordDependencyParser(path_to_jar=path_to_jar, path_to_models_jar=path_to_models_jar)\n",
        "\n",
        "\n",
        "\n",
        "dependency_parser = StanfordDependencyParser(path_to_jar=path_to_jar, path_to_models_jar=path_to_models_jar)\n",
        "\n",
        "result = dependency_parser.raw_parse(test1[\"Body\"][0])\n",
        "dep = next(result)\n",
        "\n",
        "parses = list(dep.triples())\n",
        "\n",
        "dep.tree().pretty_print()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6xsLxZo1LIJ",
        "outputId": "ea5cc291-87cd-4fe9-9961-b1f50b929214"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: The StanfordDependencyParser will be deprecated\n",
            "Please use \u001b[91mnltk.parse.corenlp.CoreNLPDependencyParser\u001b[0m instead.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: The StanfordDependencyParser will be deprecated\n",
            "Please use \u001b[91mnltk.parse.corenlp.CoreNLPDependencyParser\u001b[0m instead.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 believe                                                                    \n",
            "  __________________________________________________|_______                                                                 \n",
            " |   |                                                   brought                                                            \n",
            " |   |    __________________________________________________|_____________________________                                   \n",
            " |   |   |      Pant                        have                                       decided                              \n",
            " |   |   |    ___|______       ______________|______                        ______________|_____________                     \n",
            " |   |   |   |          DK    |    |    |         hander                   |   |                      become                \n",
            " |   |   |   |          |     |    |    |     ______|_____________         |   |     ___________________|_________           \n",
            " |   |   |   |       instead  |    |    so   |      |            team      |  mfer  |          hander            get        \n",
            " |   |   |   |          |     |    |    |    |      |        _____|____    |   |    |      ______|______       ___|_____     \n",
            "Can  t   we  in         of    we could that  a     left     in        the and the   to    a           right  and out instead\n",
            "\n"
          ]
        }
      ]
    }
  ]
}